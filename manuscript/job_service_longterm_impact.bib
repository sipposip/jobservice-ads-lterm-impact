
@article{/content/paper/726fd39d-en,
  title = {Hello, {{World}}: {{Artificial}} Intelligence and Its Use in the Public Secto},
  author = {Berryhill, Jamie and Heang, K{\'e}vin Kok and Clogher, Rob and McBride, Keegan},
  year = {2019},
  number = {36},
  doi = {https://doi.org/10.1787/726fd39d-en},
  file = {/home/sscher/Zotero/storage/J35BGIA4/2019 - Hello, World Artificial intelligence and its use .pdf}
}

@article{allhutterAlgorithmicProfilingJob2020,
  title = {Algorithmic {{Profiling}} of {{Job Seekers}} in {{Austria}}: {{How Austerity Politics Are Made Effective}}},
  shorttitle = {Algorithmic {{Profiling}} of {{Job Seekers}} in {{Austria}}},
  author = {Allhutter, Doris and Cech, Florian and Fischer, Fabian and Grill, Gabriel and Mager, Astrid},
  year = {2020},
  journal = {Frontiers in Big Data},
  volume = {3},
  publisher = {{Frontiers}},
  issn = {2624-909X},
  doi = {10.3389/fdata.2020.00005},
  abstract = {As of 2020, the Public Employment Service Austria (AMS) makes use of algorithmic profiling of job seekers to increase the efficiency of its counselling process and the effectivity of active labor market programs. Based on a statistical model of job seekers' prospects on the labor market, the system - that has become known as the AMS algorithm - is designed to classify clients of the AMS into three categories: those with high chances to find a job within half a year, those with mediocre prospects on the job market, and those clients with a bad outlook of employment in the next two years. Depending on the category a particular job seeker is classified under they will be offered differing support in (re)entering the labor market. Based in science and technology studies, critical data studies and research on fairness, accountability and transparency of algorithmic systems, this paper examines the inherent politics of the AMS algorithm. An in-depth analysis of relevant technical documentation and policy documents investigates crucial conceptual, technical and social implications of the system. The analysis shows how the design of the algorithm is influenced by technical affordances, but also by social values, norms, and goals. A discussion of the tensions, challenges and possible biases that the system entails calls into question the objectivity and neutrality of data claims and of high hopes pinned on evidence-based decision-making. In this way, the paper sheds light on the co-production of (semi)automated managerial practices in employment agencies and the framing of unemployment under austerity politics.},
  langid = {english},
  keywords = {Algorithmic Profiling,Austerity politics,Austria,big data,Co-production,critical data studies,Public employment service,qualitative research},
  file = {/home/sscher/Zotero/storage/395M3WTA/Allhutter et al. - 2020 - Algorithmic Profiling of Job Seekers in Austria H.pdf}
}

@article{allhutterAMSALGORITHMUSSoziotechnischeAnalyse2020,
  title = {{DER AMS-ALGORITHMUS Eine Soziotechnische Analyse des Arbeitsmarktchancen-Assistenz-Systems (AMAS)}},
  author = {Allhutter, Doris and Mager, Astrid and Cech, Florian and Fischer, Fabien and Grill, Gabriel},
  year = {2020},
  month = nov,
  journal = {ITA-Projektbericht},
  issn = {1819-1320},
  langid = {german}
}

@techreport{arrowTheoryDiscrimination1971,
  type = {Working {{Paper}}},
  title = {The {{Theory}} of {{Discrimination}}},
  author = {Arrow, Kenneth},
  year = {1971},
  month = oct,
  number = {403},
  institution = {{Princeton University, Department of Economics, Industrial Relations Section.}},
  file = {/home/sscher/Zotero/storage/Q4CH2AC2/Arrow - 1971 - The Theory of Discrimination.pdf;/home/sscher/Zotero/storage/U7WC6HHK/30a.html}
}

@article{biondoTalentVsLuck2018,
  title = {Talent vs {{Luck}}: The Role of Randomness in Success and Failure},
  shorttitle = {Talent vs {{Luck}}},
  author = {Biondo, A. Pluchino A. E. and Rapisarda, A.},
  year = {2018},
  month = may,
  journal = {Advances in Complex Systems},
  volume = {21},
  number = {03n04},
  eprint = {1802.07068},
  eprinttype = {arxiv},
  pages = {1850014},
  issn = {0219-5259, 1793-6802},
  doi = {10.1142/S0219525918500145},
  abstract = {The largely dominant meritocratic paradigm of highly competitive Western cultures is rooted on the belief that success is due mainly, if not exclusively, to personal qualities such as talent, intelligence, skills, smartness, efforts, willfulness, hard work or risk taking. Sometimes, we are willing to admit that a certain degree of luck could also play a role in achieving significant material success. But, as a matter of fact, it is rather common to underestimate the importance of external forces in individual successful stories. It is very well known that intelligence (or, more in general, talent and personal qualities) exhibits a Gaussian distribution among the population, whereas the distribution of wealth - often considered a proxy of success - follows typically a power law (Pareto law), with a large majority of poor people and a very small number of billionaires. Such a discrepancy between a Normal distribution of inputs, with a typical scale (the average talent or intelligence), and the scale invariant distribution of outputs, suggests that some hidden ingredient is at work behind the scenes. In this paper, with the help of a very simple agent-based toy model, we suggest that such an ingredient is just randomness. In particular, we show that, if it is true that some degree of talent is necessary to be successful in life, almost never the most talented people reach the highest peaks of success, being overtaken by mediocre but sensibly luckier individuals. As to our knowledge, this counterintuitive result - although implicitly suggested between the lines in a vast literature - is quantified here for the first time. It sheds new light on the effectiveness of assessing merit on the basis of the reached level of success and underlines the risks of distributing excessive honors or resources to people who, at the end of the day, could have been simply luckier than others. With the help of this model, several policy hypotheses are also addressed and compared to show the most efficient strategies for public funding of research in order to improve meritocracy, diversity and innovation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Physics - Physics and Society},
  file = {/home/sscher/Zotero/storage/NTGV7UA5/Biondo and Rapisarda - 2018 - Talent vs Luck the role of randomness in success .pdf}
}

@article{blattnerHowCostlyNoise2021,
  title = {How {{Costly}} Is {{Noise}}? {{Data}} and {{Disparities}} in {{Consumer Credit}}},
  shorttitle = {How {{Costly}} Is {{Noise}}?},
  author = {Blattner, Laura and Nelson, Scott},
  year = {2021},
  month = may,
  journal = {arXiv:2105.07554 [cs, econ, q-fin]},
  eprint = {2105.07554},
  eprinttype = {arxiv},
  primaryclass = {cs, econ, q-fin},
  abstract = {We show that lenders face more uncertainty when assessing default risk of historically under-served groups in US credit markets and that this information disparity is a quantitatively important driver of inefficient and unequal credit market outcomes. We first document that widely used credit scores are statistically noisier indicators of default risk for historically under-served groups. This noise emerges primarily through the explanatory power of the underlying credit report data (e.g., thin credit files), not through issues with model fit (e.g., the inability to include protected class in the scoring model). Estimating a structural model of lending with heterogeneity in information, we quantify the gains from addressing these information disparities for the US mortgage market. We find that equalizing the precision of credit scores can reduce disparities in approval rates and in credit misallocation for disadvantaged groups by approximately half.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Economics - General Economics},
  file = {/home/sscher/Zotero/storage/XV7VVWA7/Blattner and Nelson - 2021 - How Costly is Noise Data and Disparities in Consu.pdf;/home/sscher/Zotero/storage/IFZXMTG7/2105.html}
}

@article{chaturvediAgentbasedSimulationComputational2005,
  title = {Agent-Based Simulation for Computational Experimentation: {{Developing}} an Artificial Labor Market},
  shorttitle = {Agent-Based Simulation for Computational Experimentation},
  author = {Chaturvedi, Alok and Mehta, Shailendra and Dolk, Daniel and Ayer, Rick},
  year = {2005},
  month = nov,
  journal = {European Journal of Operational Research},
  series = {Advances in {{Complex Systems Modeling}}},
  volume = {166},
  number = {3},
  pages = {694--716},
  issn = {0377-2217},
  doi = {10.1016/j.ejor.2004.03.040},
  abstract = {This paper discusses the creation of an artificial labor market (ALM) as an agent-based simulation model. We trace the development of the ALM by adapting the traditional simulation life cycle into two main parts: the model phase and the simulation phase. In the modeling phase of the life cycle, we focus upon agent representation and specification within the virtual world. In the simulation phase, we discuss the use of scenario planning as the experimentation vehicle. Throughout, we use military recruit market as an example to illustrate the methodology. The benefits of the ALM are (1) it provides a virtual world for continuous computational experimentation, (2) it supports market segmentation by allowing ``drilldowns'' to finer and finer levels of granularity, and (3) when connected via a common OLAP interface to a ``real world'' counterpart, it facilitates a tightly integrated, persistent, ``sense and respond'' decision support functionality.},
  langid = {english},
  keywords = {Artificial intelligence,Decision support systems,Economics,Modelling systems and languages,Simulation},
  file = {/home/sscher/Zotero/storage/WSX5MSBU/Chaturvedi et al. - 2005 - Agent-based simulation for computational experimen.pdf;/home/sscher/Zotero/storage/GD797J86/S0377221704004102.html}
}

@inproceedings{damourFairnessNotStatic2020,
  title = {Fairness Is Not Static: Deeper Understanding of Long Term Fairness via Simulation Studies},
  shorttitle = {Fairness Is Not Static},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {D'Amour, Alexander and Srinivasan, Hansa and Atwood, James and Baljekar, Pallavi and Sculley, D. and Halpern, Yoni},
  year = {2020},
  month = jan,
  series = {{{FAT}}* '20},
  pages = {525--534},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3351095.3372878},
  abstract = {As machine learning becomes increasingly incorporated within high impact decision ecosystems, there is a growing need to understand the long-term behaviors of deployed ML-based decision systems and their potential consequences. Most approaches to understanding or improving the fairness of these systems have focused on static settings without considering long-term dynamics. This is understandable; long term dynamics are hard to assess, particularly because they do not align with the traditional supervised ML research framework that uses fixed data sets. To address this structural difficulty in the field, we advocate for the use of simulation as a key tool in studying the fairness of algorithms. We explore three toy examples of dynamical systems that have been previously studied in the context of fair decision making for bank loans, college admissions, and allocation of attention. By analyzing how learning agents interact with these systems in simulation, we are able to extend previous work, showing that static or single-step analyses do not give a complete picture of the long-term consequences of an ML-based decision system. We provide an extensible open-source software framework for implementing fairness-focused simulation studies and further reproducible research, available at https://github.com/google/ml-fairness-gym.},
  isbn = {978-1-4503-6936-7},
  file = {/home/sscher/Zotero/storage/S5MFRIVD/D'Amour et al. - 2020 - Fairness is not static deeper understanding of lo.pdf}
}

@article{ensignRunawayFeedbackLoops,
  title = {Runaway {{Feedback Loops}} in {{Predictive Policing}}},
  author = {Ensign, Danielle and Friedler, Sorelle A and Neville, Scott and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  pages = {12},
  abstract = {Predictive policing systems are increasingly used to determine how to allocate police across a city in order to best prevent crime. Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated. Such systems have been empirically shown to be susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate.},
  langid = {english},
  file = {/home/sscher/Zotero/storage/DNEC5ATN/Ensign et al. - Runaway Feedback Loops in Predictive Policing.pdf}
}

@book{europeancommission.directorategeneralforjusticeandconsumers.ReversingBurdenProof2015,
  title = {Reversing the Burden of Proof: Practical Dilemmas at the {{European}} and National Level.},
  shorttitle = {Reversing the Burden of Proof},
  author = {{European Commission. Directorate General for Justice and Consumers.} and {European Network of Legal Experts in the Non Discrimination Field.}},
  year = {2015},
  publisher = {{Publications Office}},
  address = {{LU}},
  langid = {english},
  file = {/home/sscher/Zotero/storage/NHYGPXG6/2005.05906.pdf}
}

@misc{europeanunionagencyforfundamentalrightsBigDataDiscriminationDatasupported2018,
  title = {\#{{BigData}}: {{Discrimination}} in Data-Supported Decision Making},
  shorttitle = {\#{{BigData}}},
  author = {{European Union, Agency for Fundamental Rights}},
  year = {2018},
  publisher = {{Koninklijke Brill NV}},
  doi = {10.1163/2210-7975_HRD-9992-20180020},
  isbn = {978-92-9474-069-4},
  langid = {english},
  file = {/home/sscher/Zotero/storage/PML58MTG/#BigData Discrimination in data-supported decisio.pdf}
}

@book{europeanunionagencyforfundamentalrightsDataQualityArtificial2019,
  title = {Data Quality and Artificial Intelligence \textendash{} Mitigating Bias and Error to Protect Fundamental Rights},
  author = {{European Union, Agency for Fundamental Rights}},
  year = {2019},
  edition = {978-92-9474-606-1},
  langid = {english},
  file = {/home/sscher/Zotero/storage/VD9ES7S2/Data quality and artificial intelligence – mitigat.pdf}
}

@book{europeanunionagencyforfundamentalrightsGettingFutureRight2020,
  title = {Getting the Future Right Artificial Intelligence and Fundamental Rights ; Report},
  author = {{European Union, Agency for Fundamental Rights}},
  year = {2020},
  isbn = {978-92-9474-861-4 978-92-9474-860-7},
  langid = {english},
  annotation = {OCLC: 1243061923},
  file = {/home/sscher/Zotero/storage/7IY8AIKT/Europäische Union - 2020 - Getting the future right artificial intelligence a.pdf}
}

@incollection{goetzLaborMarketTheory2014,
  title = {Labor {{Market Theory}} and {{Models}}},
  booktitle = {Handbook of {{Regional Science}}},
  author = {Goetz, Stephan J.},
  editor = {Fischer, Manfred M. and Nijkamp, Peter},
  year = {2014},
  pages = {35--57},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-23430-9_6},
  abstract = {This chapter reviews labor supply, demand, and equilibrium topics with the goal of showing how they determine labor market area (LMA) outcomes across geographic space. Labor supply curves are based on utility-maximizing choices between working and leisure, subject to a budget constraint, while labor demand curves are derived from the firm's production function assuming profit-maximizing behavior. The challenges of defining and empirically delimiting LMAs are examined from historical perspectives and using statistical clustering analysis, with commuting data serving as a key tool. A key distinction is drawn between functional versus homogenous regionalization problems, and a number of suitable statistical approaches are reviewed. Current models used to study differences in earnings across labor markets as well as the effects of boom and bust cycles are also discussed. An empirical technique is presented for decomposing employment change within a community into four key labor market concepts: commuting, unemployment, labor force participation, and migration.},
  isbn = {978-3-642-23430-9},
  langid = {english},
  keywords = {Indifference Curve,Labor Force Participation,Labor Force Participation Rate,Labor Market,Labor Supply},
  file = {/home/sscher/Zotero/storage/4MSHGX95/Goetz - 2014 - Labor Market Theory and Models.pdf}
}

@article{hollAMSArbeitsmarktChancenModell,
  title = {{Das AMS-Arbeitsmarkt- chancen-Modell}},
  author = {Holl, J{\"u}rgen and Kernbei{\ss}, G{\"u}nter and {Wagner-Pinter}, Michael},
  pages = {16},
  langid = {german},
  file = {/home/sscher/Zotero/storage/R6JXR5IM/Holl et al. - Das AMS-Arbeitsmarkt- chancen-Modell.pdf}
}

@incollection{holzleithnerEUrechtlicheBestimmungenDiskriminierungsverbot2017,
  title = {{EU-rechtliche Bestimmungen zum Diskriminierungsverbot}},
  booktitle = {{Handbuch Diskriminierung}},
  author = {Holzleithner, Elisabeth},
  editor = {Scherr, Albert and {El-Mafaalani}, Aladin and Y{\"u}ksel, G{\"o}k{\c c}en},
  year = {2017},
  series = {{Springer Reference Sozialwissenschaften}},
  pages = {211--237},
  publisher = {{Springer Fachmedien}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-10976-9_12},
  abstract = {Die Prinzipien der Gleichheit und der Nichtdiskriminierung haben in der Europ\"aischen Union eine herausragende Bedeutung. Aktivit\"aten des EU-Gesetzgebers haben bereits zu einer Mehrzahl von Richtlinien gef\"uhrt, die eine Bek\"ampfung von Diskriminierungen erm\"oglichen und weitergehende Ma\ss nahmen der Gleichstellung ansto\ss en sollen. Der vorliegende Text wirft einen vergleichenden Blick auf die einschl\"agigen Vertragsbestimmungen und Richtlinien: inwiefern sie konvergieren und wo sie unterschiedliche Schutzniveaus und damit auch Hierarchien etablieren. Dabei gilt es, die Spezifika der einzelnen Diskriminierungsgr\"unde herauszuarbeiten, sie aber auch in ihrem Zusammenwirken in den Blick zu nehmen (,,Mehrfachdiskriminierung``). Abschlie\ss end werden die Vorgaben f\"ur Institutionen und Verfahren dargelegt.},
  isbn = {978-3-658-10976-9},
  langid = {german},
  keywords = {Diskriminierungstatbestände,EU-Grundrechtecharta,Europäische Union,Mehrfachdiskriminierung,Schutzniveaus}
}

@inproceedings{huShorttermInterventionLongterm2018,
  title = {A {{Short-term Intervention}} for {{Long-term Fairness}} in the {{Labor Market}}},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}} on {{World Wide Web}} - {{WWW}} '18},
  author = {Hu, Lily and Chen, Yiling},
  year = {2018},
  pages = {1389--1398},
  publisher = {{ACM Press}},
  address = {{Lyon, France}},
  doi = {10.1145/3178876.3186044},
  abstract = {The persistence of racial inequality in the U.S. labor market against a general backdrop of formal equality of opportunity is a troubling phenomenon that has significant ramifications on the design of hiring policies. In this paper, we show that current group disparate outcomes may be immovable even when hiring decisions are bound by an input-output notion of ``individual fairness.'' Instead, we construct a dynamic reputational model of the labor market that illustrates the reinforcing nature of asymmetric outcomes resulting from groups' divergent accesses to resources and as a result, investment choices. To address these disparities, we adopt a dual labor market composed of a Temporary Labor Market (TLM), in which firms' hiring strategies are constrained to ensure statistical parity of workers granted entry into the pipeline, and a Permanent Labor Market (PLM), in which firms hire top performers as desired. Individual worker reputations produce externalities for their group; the corresponding feedback loop raises the collective reputation of the initially disadvantaged group via a TLM fairness intervention that need not be permanent. We show that such a restriction on hiring practices induces an equilibrium that, under particular market conditions, Pareto-dominates those arising from strategies that statistically discriminate or employ a ``group-blind'' criterion. The enduring nature of equilibria that are both inequitable and Pareto suboptimal suggests that fairness interventions beyond procedural checks of hiring decisions will be of critical importance in a world where machines play a greater role in the employment process.},
  isbn = {978-1-4503-5639-8},
  langid = {english},
  file = {/home/sscher/Zotero/storage/QEZB7UX6/Hu and Chen - 2018 - A Short-term Intervention for Long-term Fairness i.pdf}
}

@inproceedings{kasyFairnessEqualityPower2021,
  title = {Fairness, {{Equality}}, and {{Power}} in {{Algorithmic Decision-Making}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Kasy, Maximilian and Abebe, Rediet},
  year = {2021},
  month = mar,
  series = {{{FAccT}} '21},
  pages = {576--586},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3442188.3445919},
  abstract = {Much of the debate on the impact of algorithms is concerned with fairness, defined as the absence of discrimination for individuals with the same "merit." Drawing on the theory of justice, we argue that leading notions of fairness suffer from three key limitations: they legitimize inequalities justified by "merit;" they are narrowly bracketed, considering only differences of treatment within the algorithm; and they consider between-group and not within-group differences. We contrast this fairness-based perspective with two alternate perspectives: the first focuses on inequality and the causal impact of algorithms and the second on the distribution of power. We formalize these perspectives drawing on techniques from causal inference and empirical economics, and characterize when they give divergent evaluations. We present theoretical results and empirical examples which demonstrate this tension. We further use these insights to present a guide for algorithmic auditing and discuss the importance of inequality- and power-centered frameworks in algorithmic decision-making.},
  isbn = {978-1-4503-8309-7},
  keywords = {Algorithmic fairness,auditing,empirical economics,inequality,power},
  file = {/home/sscher/Zotero/storage/T8Q47NAK/Kasy and Abebe - 2021 - Fairness, Equality, and Power in Algorithmic Decis.pdf}
}

@article{lopezReinforcingIntersectionalInequality2019,
  title = {Reinforcing {{Intersectional Inequality}} via the {{AMS Algorithm}} in {{Austria}}},
  author = {Lopez, Paola},
  year = {2019},
  pages = {21},
  abstract = {This paper examines the so-called AMS Algorithm from a mathematical perspective: this algorithmic system constitutes a predictive model that will be used by the Public Employment Service Austria (AMS) starting in 2020 to algorithmically classify job-seekers into three groups, each with different access to AMS support resources, according to their predicted chances on the labour market. Since the features gender, age, childcare responsibilities, disability and citizenship are explicitly implemented in the model and are thus linked to the availability of resources, this algorithmic system is to be considered very problematic. This paper is part of an ongoing research project, and it identifies three conceptual building blocks of the AMS Algorithm that are all based on human decisions and in which obvious societal bias can be located. Furthermore, this model is used as an illustrative example to address the larger question of what can be expected when predictions are made that are based solely on data that describes the past: If the predictions by these models result in unquestioned and confirmatory measures such as the redistribution of resources, a reproduction and reinforcement of inequality is possible. If these measures are now applied to vulnerable and highly dependent target groups, such as job-seekers, it will be more drastic: In a first step, these predictive models depict the reality of discrimination, then, in a second step, normatively reinforce it as a supposedly objective fact and finally, in a third step, return it to the social sphere by means of the resulting measures.},
  langid = {english},
  file = {/home/sscher/Zotero/storage/GERKMISS/Lopez - 2019 - Reinforcing Intersectional Inequality via the AMS .pdf}
}

@book{neugartAgentBasedModelsLabor2018,
  title = {Agent-{{Based Models}} of the {{Labor Market}}},
  author = {Neugart, Michael and Richiardi, Matteo},
  editor = {Chen, Shu-Heng and Kaboudan, Mak and Du, Ye-Rong},
  year = {2018},
  month = feb,
  volume = {1},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199844371.013.44},
  abstract = {We review the literature on agent-based labor market models by tracing its roots to the microsimulation literature, and surveying a selection of contributions made since the work by Bergmann (1974) and Eliasson (1976). Agent-based models have been applied to explain stylized facts of labor markets as well as for labor market policy evaluations. They also constitute a major part in agent-based macroeconomic models. Besides reviewing the various results achieved, we discuss modeling choices with respect to agents' behavior and the structure of interaction. Our overall assessment is that agent-based labor market models have given us valuable insights into the functioning of labor markets and the consequences of labor market policies, and that they will increasingly become an essential tool of analysis, in particular when the construction of large macro-models is involved.},
  langid = {english},
  file = {/home/sscher/Zotero/storage/HB8C48SQ/Neugart and Richiardi - 2018 - Agent-Based Models of the Labor Market.pdf}
}

@article{reisman2018algorithmic,
  title = {Algorithmic Impact Assessments: {{A}} Practical Framework for Public Agency Accountability},
  author = {Reisman, Dillon and Schultz, Jason and Crawford, Kate and Whittaker, Meredith},
  year = {2018},
  journal = {AI Now Institute},
  pages = {1--22}
}

@article{wachterWhyFairnessCannot2020,
  title = {Why {{Fairness Cannot Be Automated}}: {{Bridging}} the {{Gap Between EU Non-Discrimination Law}} and {{AI}}},
  shorttitle = {Why {{Fairness Cannot Be Automated}}},
  author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  year = {2020},
  journal = {SSRN Electronic Journal},
  eprint = {2005.05906},
  eprinttype = {arxiv},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3547922},
  abstract = {This article identifies a critical incompatibility between European notions of discrimination and existing statistical measures of fairness. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. We propose "conditional demographic disparity" (CDD) as a standard baseline statistical measurement that aligns with the European Court of Justice's "gold standard." Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law. N.B. Abridged abstract},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/sscher/Zotero/storage/G4QC6EMA/Wachter et al. - 2020 - Why Fairness Cannot Be Automated Bridging the Gap.pdf;/home/sscher/Zotero/storage/2H6VINJQ/2005.html}
}


