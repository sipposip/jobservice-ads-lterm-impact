
@article{allhutterAlgorithmicProfilingJob2020,
  title = {Algorithmic {{Profiling}} of {{Job Seekers}} in {{Austria}}: {{How Austerity Politics Are Made Effective}}},
  shorttitle = {Algorithmic {{Profiling}} of {{Job Seekers}} in {{Austria}}},
  author = {Allhutter, Doris and Cech, Florian and Fischer, Fabian and Grill, Gabriel and Mager, Astrid},
  year = {2020},
  volume = {3},
  publisher = {{Frontiers}},
  issn = {2624-909X},
  doi = {10.3389/fdata.2020.00005},
  abstract = {As of 2020, the Public Employment Service Austria (AMS) makes use of algorithmic profiling of job seekers to increase the efficiency of its counselling process and the effectivity of active labor market programs. Based on a statistical model of job seekers' prospects on the labor market, the system - that has become known as the AMS algorithm - is designed to classify clients of the AMS into three categories: those with high chances to find a job within half a year, those with mediocre prospects on the job market, and those clients with a bad outlook of employment in the next two years. Depending on the category a particular job seeker is classified under they will be offered differing support in (re)entering the labor market. Based in science and technology studies, critical data studies and research on fairness, accountability and transparency of algorithmic systems, this paper examines the inherent politics of the AMS algorithm. An in-depth analysis of relevant technical documentation and policy documents investigates crucial conceptual, technical and social implications of the system. The analysis shows how the design of the algorithm is influenced by technical affordances, but also by social values, norms, and goals. A discussion of the tensions, challenges and possible biases that the system entails calls into question the objectivity and neutrality of data claims and of high hopes pinned on evidence-based decision-making. In this way, the paper sheds light on the co-production of (semi)automated managerial practices in employment agencies and the framing of unemployment under austerity politics.},
  file = {/home/sscher/Zotero/storage/395M3WTA/Allhutter et al. - 2020 - Algorithmic Profiling of Job Seekers in Austria H.pdf},
  journal = {Frontiers in Big Data},
  keywords = {Algorithmic Profiling,Austerity politics,Austria,big data,Co-production,critical data studies,Public employment service,qualitative research},
  language = {English}
}

@article{biondoTalentVsLuck2018,
  title = {Talent vs {{Luck}}: The Role of Randomness in Success and Failure},
  shorttitle = {Talent vs {{Luck}}},
  author = {Biondo, A. Pluchino A. E. and Rapisarda, A.},
  year = {2018},
  month = may,
  volume = {21},
  pages = {1850014},
  issn = {0219-5259, 1793-6802},
  doi = {10.1142/S0219525918500145},
  abstract = {The largely dominant meritocratic paradigm of highly competitive Western cultures is rooted on the belief that success is due mainly, if not exclusively, to personal qualities such as talent, intelligence, skills, smartness, efforts, willfulness, hard work or risk taking. Sometimes, we are willing to admit that a certain degree of luck could also play a role in achieving significant material success. But, as a matter of fact, it is rather common to underestimate the importance of external forces in individual successful stories. It is very well known that intelligence (or, more in general, talent and personal qualities) exhibits a Gaussian distribution among the population, whereas the distribution of wealth - often considered a proxy of success - follows typically a power law (Pareto law), with a large majority of poor people and a very small number of billionaires. Such a discrepancy between a Normal distribution of inputs, with a typical scale (the average talent or intelligence), and the scale invariant distribution of outputs, suggests that some hidden ingredient is at work behind the scenes. In this paper, with the help of a very simple agent-based toy model, we suggest that such an ingredient is just randomness. In particular, we show that, if it is true that some degree of talent is necessary to be successful in life, almost never the most talented people reach the highest peaks of success, being overtaken by mediocre but sensibly luckier individuals. As to our knowledge, this counterintuitive result - although implicitly suggested between the lines in a vast literature - is quantified here for the first time. It sheds new light on the effectiveness of assessing merit on the basis of the reached level of success and underlines the risks of distributing excessive honors or resources to people who, at the end of the day, could have been simply luckier than others. With the help of this model, several policy hypotheses are also addressed and compared to show the most efficient strategies for public funding of research in order to improve meritocracy, diversity and innovation.},
  archiveprefix = {arXiv},
  eprint = {1802.07068},
  eprinttype = {arxiv},
  file = {/home/sscher/Zotero/storage/NTGV7UA5/Biondo and Rapisarda - 2018 - Talent vs Luck the role of randomness in success .pdf},
  journal = {Advances in Complex Systems},
  keywords = {Physics - Physics and Society},
  language = {en},
  number = {03n04}
}

@article{blattnerHowCostlyNoise2021,
  title = {How {{Costly}} Is {{Noise}}? {{Data}} and {{Disparities}} in {{Consumer Credit}}},
  shorttitle = {How {{Costly}} Is {{Noise}}?},
  author = {Blattner, Laura and Nelson, Scott},
  year = {2021},
  month = may,
  abstract = {We show that lenders face more uncertainty when assessing default risk of historically under-served groups in US credit markets and that this information disparity is a quantitatively important driver of inefficient and unequal credit market outcomes. We first document that widely used credit scores are statistically noisier indicators of default risk for historically under-served groups. This noise emerges primarily through the explanatory power of the underlying credit report data (e.g., thin credit files), not through issues with model fit (e.g., the inability to include protected class in the scoring model). Estimating a structural model of lending with heterogeneity in information, we quantify the gains from addressing these information disparities for the US mortgage market. We find that equalizing the precision of credit scores can reduce disparities in approval rates and in credit misallocation for disadvantaged groups by approximately half.},
  archiveprefix = {arXiv},
  eprint = {2105.07554},
  eprinttype = {arxiv},
  file = {/home/sscher/Zotero/storage/XV7VVWA7/Blattner and Nelson - 2021 - How Costly is Noise Data and Disparities in Consu.pdf;/home/sscher/Zotero/storage/IFZXMTG7/2105.html},
  journal = {arXiv:2105.07554 [cs, econ, q-fin]},
  keywords = {Computer Science - Machine Learning,Economics - General Economics},
  primaryclass = {cs, econ, q-fin}
}

@inproceedings{damourFairnessNotStatic2020,
  title = {Fairness Is Not Static: Deeper Understanding of Long Term Fairness via Simulation Studies},
  shorttitle = {Fairness Is Not Static},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {D'Amour, Alexander and Srinivasan, Hansa and Atwood, James and Baljekar, Pallavi and Sculley, D. and Halpern, Yoni},
  year = {2020},
  month = jan,
  pages = {525--534},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3351095.3372878},
  abstract = {As machine learning becomes increasingly incorporated within high impact decision ecosystems, there is a growing need to understand the long-term behaviors of deployed ML-based decision systems and their potential consequences. Most approaches to understanding or improving the fairness of these systems have focused on static settings without considering long-term dynamics. This is understandable; long term dynamics are hard to assess, particularly because they do not align with the traditional supervised ML research framework that uses fixed data sets. To address this structural difficulty in the field, we advocate for the use of simulation as a key tool in studying the fairness of algorithms. We explore three toy examples of dynamical systems that have been previously studied in the context of fair decision making for bank loans, college admissions, and allocation of attention. By analyzing how learning agents interact with these systems in simulation, we are able to extend previous work, showing that static or single-step analyses do not give a complete picture of the long-term consequences of an ML-based decision system. We provide an extensible open-source software framework for implementing fairness-focused simulation studies and further reproducible research, available at https://github.com/google/ml-fairness-gym.},
  file = {/home/sscher/Zotero/storage/S5MFRIVD/D'Amour et al. - 2020 - Fairness is not static deeper understanding of lo.pdf},
  isbn = {978-1-4503-6936-7},
  series = {{{FAT}}* '20}
}

@article{ensignRunawayFeedbackLoops,
  title = {Runaway {{Feedback Loops}} in {{Predictive Policing}}},
  author = {Ensign, Danielle and Friedler, Sorelle A and Neville, Scott and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  pages = {12},
  abstract = {Predictive policing systems are increasingly used to determine how to allocate police across a city in order to best prevent crime. Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated. Such systems have been empirically shown to be susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate.},
  file = {/home/sscher/Zotero/storage/DNEC5ATN/Ensign et al. - Runaway Feedback Loops in Predictive Policing.pdf},
  language = {en}
}

@incollection{goetzLaborMarketTheory2014,
  title = {Labor {{Market Theory}} and {{Models}}},
  booktitle = {Handbook of {{Regional Science}}},
  author = {Goetz, Stephan J.},
  editor = {Fischer, Manfred M. and Nijkamp, Peter},
  year = {2014},
  pages = {35--57},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-23430-9_6},
  abstract = {This chapter reviews labor supply, demand, and equilibrium topics with the goal of showing how they determine labor market area (LMA) outcomes across geographic space. Labor supply curves are based on utility-maximizing choices between working and leisure, subject to a budget constraint, while labor demand curves are derived from the firm's production function assuming profit-maximizing behavior. The challenges of defining and empirically delimiting LMAs are examined from historical perspectives and using statistical clustering analysis, with commuting data serving as a key tool. A key distinction is drawn between functional versus homogenous regionalization problems, and a number of suitable statistical approaches are reviewed. Current models used to study differences in earnings across labor markets as well as the effects of boom and bust cycles are also discussed. An empirical technique is presented for decomposing employment change within a community into four key labor market concepts: commuting, unemployment, labor force participation, and migration.},
  file = {/home/sscher/Zotero/storage/4MSHGX95/Goetz - 2014 - Labor Market Theory and Models.pdf},
  isbn = {978-3-642-23430-9},
  keywords = {Indifference Curve,Labor Force Participation,Labor Force Participation Rate,Labor Market,Labor Supply},
  language = {en}
}

@article{hollAMSArbeitsmarktChancenModell,
  title = {{Das AMS-Arbeitsmarkt- chancen-Modell}},
  author = {Holl, J{\"u}rgen and Kernbei{\ss}, G{\"u}nter and {Wagner-Pinter}, Michael},
  pages = {16},
  file = {/home/sscher/Zotero/storage/R6JXR5IM/Holl et al. - Das AMS-Arbeitsmarkt- chancen-Modell.pdf},
  language = {de}
}

@incollection{holzleithnerEUrechtlicheBestimmungenDiskriminierungsverbot2017,
  title = {{EU-rechtliche Bestimmungen zum Diskriminierungsverbot}},
  booktitle = {{Handbuch Diskriminierung}},
  author = {Holzleithner, Elisabeth},
  editor = {Scherr, Albert and {El-Mafaalani}, Aladin and Y{\"u}ksel, G{\"o}k{\c c}en},
  year = {2017},
  pages = {211--237},
  publisher = {{Springer Fachmedien}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-658-10976-9_12},
  abstract = {Die Prinzipien der Gleichheit und der Nichtdiskriminierung haben in der Europ\"aischen Union eine herausragende Bedeutung. Aktivit\"aten des EU-Gesetzgebers haben bereits zu einer Mehrzahl von Richtlinien gef\"uhrt, die eine Bek\"ampfung von Diskriminierungen erm\"oglichen und weitergehende Ma\ss nahmen der Gleichstellung ansto\ss en sollen. Der vorliegende Text wirft einen vergleichenden Blick auf die einschl\"agigen Vertragsbestimmungen und Richtlinien: inwiefern sie konvergieren und wo sie unterschiedliche Schutzniveaus und damit auch Hierarchien etablieren. Dabei gilt es, die Spezifika der einzelnen Diskriminierungsgr\"unde herauszuarbeiten, sie aber auch in ihrem Zusammenwirken in den Blick zu nehmen (,,Mehrfachdiskriminierung``). Abschlie\ss end werden die Vorgaben f\"ur Institutionen und Verfahren dargelegt.},
  isbn = {978-3-658-10976-9},
  keywords = {Diskriminierungstatbestände,EU-Grundrechtecharta,Europäische Union,Mehrfachdiskriminierung,Schutzniveaus},
  language = {de},
  series = {{Springer Reference Sozialwissenschaften}}
}

@inproceedings{kasyFairnessEqualityPower2021,
  title = {Fairness, {{Equality}}, and {{Power}} in {{Algorithmic Decision}}-{{Making}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Kasy, Maximilian and Abebe, Rediet},
  year = {2021},
  month = mar,
  pages = {576--586},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3442188.3445919},
  abstract = {Much of the debate on the impact of algorithms is concerned with fairness, defined as the absence of discrimination for individuals with the same "merit." Drawing on the theory of justice, we argue that leading notions of fairness suffer from three key limitations: they legitimize inequalities justified by "merit;" they are narrowly bracketed, considering only differences of treatment within the algorithm; and they consider between-group and not within-group differences. We contrast this fairness-based perspective with two alternate perspectives: the first focuses on inequality and the causal impact of algorithms and the second on the distribution of power. We formalize these perspectives drawing on techniques from causal inference and empirical economics, and characterize when they give divergent evaluations. We present theoretical results and empirical examples which demonstrate this tension. We further use these insights to present a guide for algorithmic auditing and discuss the importance of inequality- and power-centered frameworks in algorithmic decision-making.},
  file = {/home/sscher/Zotero/storage/T8Q47NAK/Kasy and Abebe - 2021 - Fairness, Equality, and Power in Algorithmic Decis.pdf},
  isbn = {978-1-4503-8309-7},
  keywords = {Algorithmic fairness,auditing,empirical economics,inequality,power},
  series = {{{FAccT}} '21}
}

@article{lopezReinforcingIntersectionalInequality2019,
  title = {Reinforcing {{Intersectional Inequality}} via the {{AMS Algorithm}} in {{Austria}}},
  author = {Lopez, Paola},
  year = {2019},
  pages = {21},
  abstract = {This paper examines the so-called AMS Algorithm from a mathematical perspective: this algorithmic system constitutes a predictive model that will be used by the Public Employment Service Austria (AMS) starting in 2020 to algorithmically classify job-seekers into three groups, each with different access to AMS support resources, according to their predicted chances on the labour market. Since the features gender, age, childcare responsibilities, disability and citizenship are explicitly implemented in the model and are thus linked to the availability of resources, this algorithmic system is to be considered very problematic. This paper is part of an ongoing research project, and it identifies three conceptual building blocks of the AMS Algorithm that are all based on human decisions and in which obvious societal bias can be located. Furthermore, this model is used as an illustrative example to address the larger question of what can be expected when predictions are made that are based solely on data that describes the past: If the predictions by these models result in unquestioned and confirmatory measures such as the redistribution of resources, a reproduction and reinforcement of inequality is possible. If these measures are now applied to vulnerable and highly dependent target groups, such as job-seekers, it will be more drastic: In a first step, these predictive models depict the reality of discrimination, then, in a second step, normatively reinforce it as a supposedly objective fact and finally, in a third step, return it to the social sphere by means of the resulting measures.},
  file = {/home/sscher/Zotero/storage/GERKMISS/Lopez - 2019 - Reinforcing Intersectional Inequality via the AMS .pdf},
  language = {en}
}

@article{wachterWhyFairnessCannot2020,
  title = {Why {{Fairness Cannot Be Automated}}: {{Bridging}} the {{Gap Between EU Non}}-{{Discrimination Law}} and {{AI}}},
  shorttitle = {Why {{Fairness Cannot Be Automated}}},
  author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  year = {2020},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3547922},
  abstract = {This article identifies a critical incompatibility between European notions of discrimination and existing statistical measures of fairness. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. We propose "conditional demographic disparity" (CDD) as a standard baseline statistical measurement that aligns with the European Court of Justice's "gold standard." Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law. N.B. Abridged abstract},
  archiveprefix = {arXiv},
  eprint = {2005.05906},
  eprinttype = {arxiv},
  file = {/home/sscher/Zotero/storage/G4QC6EMA/Wachter et al. - 2020 - Why Fairness Cannot Be Automated Bridging the Gap.pdf;/home/sscher/Zotero/storage/2H6VINJQ/2005.html},
  journal = {SSRN Electronic Journal},
  keywords = {Computer Science - Artificial Intelligence}
}


